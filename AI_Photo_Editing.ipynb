{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+mt7XVsd41VzRM1SeyN2m"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AI photo editing**"
      ],
      "metadata": {
        "id": "BJbVO-yHbb_8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKZakRWsbbb1"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import SamModel, SamProcessor\n",
        "from diffusers import DiffusionPipeline, AutoPipelineForText2Image, AutoPipelineForInpainting\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SAM model as we have seen in the class\n",
        "\n",
        "Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(Device)\n",
        "model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(Device)\n",
        "\n",
        "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\", torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "cW3wIQBObrB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the mask\n",
        "def mask_to_rgb(mask):\n",
        "    \"\"\"\n",
        "    Transforms a binary mask into an RGBA image for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    bg_transparent = np.zeros(mask.shape + (4, ), dtype=np.uint8)\n",
        "\n",
        "    # Color the area we will replace in green\n",
        "    # (this vector is [Red, Green, Blue, Alpha])\n",
        "    bg_transparent[mask == 1] = [0, 255, 0, 127]\n",
        "\n",
        "    return bg_transparent\n",
        "\n",
        "\n",
        "def get_processed_inputs(image, input_points):\n",
        "\n",
        "    # Use the processor to generate the right inputs for SAM\n",
        "    inputs = processor(images=image, input_points=input_points, return_tensors=\"pt\").to(Device)\n",
        "\n",
        "    # Call SAM\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Now let's post process the outputs of SAM to obtain the masks\n",
        "    masks = processor.image_processor.post_process_masks(\n",
        "       outputs.pred_masks.cpu(),\n",
        "       inputs[\"original_sizes\"].cpu(),\n",
        "       inputs[\"reshaped_input_sizes\"].cpu()\n",
        "    )\n",
        "\n",
        "    # Here we select the mask with the highest score\n",
        "    # as the mask we will use. You can experiment with also\n",
        "    # other selection criteria, for example the largest mask\n",
        "    # instead of the most confident mask\n",
        "    best_mask = masks[0][0][outputs.iou_scores.argmax()]\n",
        "\n",
        "    # NOTE: we invert the mask by using the ~ operator because\n",
        "    # so that the subject pixels will have a value of 0 and the\n",
        "    # background pixels a value of 1. This will make it more convenient\n",
        "    # to infill the background\n",
        "    return ~best_mask.cpu().numpy()"
      ],
      "metadata": {
        "id": "oSnt-SyabrMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"car.png\").convert(\"RGB\").resize((512, 512))\n",
        "# These are the coordinates of two points on the car\n",
        "input_points = [[[150, 170], [300, 250]]]\n",
        "mask = get_processed_inputs(raw_image, input_points)\n",
        "Image.fromarray(mask_to_rgb(mask)).resize((128, 128))"
      ],
      "metadata": {
        "id": "KqA4Ah14brPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inpainting"
      ],
      "metadata": {
        "id": "DyeqYZu8d95U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = AutoPipelineForInpainting.from_pretrained(\n",
        "    'diffusers/stable-diffusion-xl-1.0-inpainting-0.1',\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipeline.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "LF2nUVv3brR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inpaint(raw_image, input_mask, prompt, negative_prompt=None, seed=74294536, cfgs=7):\n",
        "\n",
        "    mask_image = Image.fromarray(input_mask)\n",
        "\n",
        "    rand_gen = torch.manual_seed(seed)\n",
        "\n",
        "    image = pipeline(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=raw_image,\n",
        "        mask_image=mask_image,\n",
        "        generator=rand_gen,\n",
        "        guidance_scale=cfgs\n",
        "    ).images[0]\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "4fxbgodnbrTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a car driving on Mars. Studio lights, 1970s\"\n",
        "negative_prompt = \"artifacts, low quality, distortion\"\n",
        "\n",
        "image = inpaint(raw_image, mask, prompt, negative_prompt)"
      ],
      "metadata": {
        "id": "0UvNieD6eeWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_image_grid([raw_image, Image.fromarray(mask_to_rgb(mask)), image.resize((512, 512))], rows=1, cols=3)\n",
        "fig"
      ],
      "metadata": {
        "id": "Af2ygXwDeh31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use some took to playing with the masks"
      ],
      "metadata": {
        "id": "zuW2CG4OeiUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}